{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import sympy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, r2_score\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.initializers import Zeros, RandomNormal\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = sorted(glob.glob('recon3D/recon3D_d*.parquet'))\n",
    "labels_files = sorted(glob.glob('labels/labels_d*.parquet'))\n",
    "\n",
    "chunk_size = 10\n",
    "data_chunks = []\n",
    "labels_chunks = []\n",
    "n_files = 0\n",
    "\n",
    "#for i in range(0, len(data_files), chunk_size):\n",
    "for i in range(0, 100, chunk_size):\n",
    "    data_chunk_files = data_files[i:i+chunk_size]\n",
    "    labels_chunk_files = labels_files[i:i+chunk_size]\n",
    "    \n",
    "    data_chunk_list = []\n",
    "    labels_chunk_list = []\n",
    "    \n",
    "    for rf, lf in zip(data_chunk_files, labels_chunk_files):\n",
    "        d = pd.read_parquet(rf)\n",
    "        l = pd.read_parquet(lf)\n",
    "        \n",
    "        data_chunk_list.append(d)\n",
    "        labels_chunk_list.append(l[['y-local', 'pt']])\n",
    "        \n",
    "        n_files += 1\n",
    "        print(f\"Processed {n_files} files\", end='\\r')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    chunk_data_df = pd.concat(data_chunk_list, ignore_index=True)\n",
    "    chunk_labels_df = pd.concat(labels_chunk_list, ignore_index=True)\n",
    "    \n",
    "    data_chunks.append(np.reshape(chunk_data_df.to_numpy(), (-1, 20, 13, 21)))\n",
    "    labels_chunks.append(chunk_labels_df)\n",
    "\n",
    "del data_chunk_list, labels_chunk_list, d, l, chunk_data_df, chunk_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "data = np.concatenate(data_chunks[:n], axis=0)\n",
    "labels = pd.concat(labels_chunks[:n], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data[0].shape[0]):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(data[0][i], aspect='auto', cmap='viridis')\n",
    "    plt.title(f'Time slice {i+1}')\n",
    "    plt.xlabel('x [pixels]')\n",
    "    plt.ylabel('y [pixels]')\n",
    "    plt.colorbar(label='cluster charge')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0_range = [(-1, 1), (-8, -6), (6, 8)]\n",
    "for r in y0_range:\n",
    "    data_y0range = data[(labels['y-local'] > r[0]) & (labels['y-local'] < r[1])]\n",
    "    labels_y0range = labels[(labels['y-local'] > r[0]) & (labels['y-local'] < r[1])]\n",
    "    \n",
    "    # take the last time slice, and sum over x to get y profile\n",
    "    y_profile = data_y0range[:, -1, :, :].sum(axis = -1)\n",
    "    \n",
    "    y_profile_low_pos = y_profile[(labels_y0range['pt'] < 0.2) & (labels_y0range['pt'] > 0)]\n",
    "    y_profile_low_neg = y_profile[(labels_y0range['pt'] > -0.2) & (labels_y0range['pt'] < 0)]\n",
    "    y_profile_high = y_profile[(labels_y0range['pt'] > 0.2) | (labels_y0range['pt'] < -0.2)]\n",
    "    \n",
    "    y_profile_low_pos_mean = y_profile_low_pos.mean(axis = 0)\n",
    "    y_profile_low_neg_mean = y_profile_low_neg.mean(axis = 0)\n",
    "    y_profile_high_mean = y_profile_high.mean(axis = 0)\n",
    "    \n",
    "    edges = np.arange(len(y_profile_low_pos_mean) + 1)\n",
    "    \n",
    "    y_profile_low_pos_mean = np.concatenate(([0], y_profile_low_pos_mean))\n",
    "    y_profile_low_neg_mean = np.concatenate(([0], y_profile_low_neg_mean))\n",
    "    y_profile_high_mean = np.concatenate(([0], y_profile_high_mean))\n",
    "    \n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.step(edges, y_profile_low_pos_mean/np.sum(y_profile_low_pos_mean), where='post', label = 'Low pT (pos)', color='red')\n",
    "    plt.step(edges, y_profile_low_neg_mean/np.sum(y_profile_low_neg_mean), where='post', label = 'Low pT (neg)', color='blue')\n",
    "    plt.step(edges, y_profile_high_mean/np.sum(y_profile_high_mean), where='post', label = 'High pT', color='black')\n",
    "    plt.title(f\"Mean cluster shape ({r[0]}mm < y0 < {r[1]}mm)\", size=10)\n",
    "    #plt.ylim(0, max(y_profile_low_neg_mean)*1.25)\n",
    "    plt.ylim(0, 0.35)\n",
    "    plt.xlabel(\"y [pixels]\")\n",
    "    plt.ylabel(\"Mean cluster charge\")\n",
    "    plt.xticks(np.arange(0, len(y_profile_low_pos_mean) + 1, 2))\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_profile = data[:, -1, :, :].sum(axis = -1)\n",
    "y_size = np.count_nonzero(y_profile, axis=1, keepdims=True)\n",
    "y_size = y_size.flatten() \n",
    "labels = labels.copy()\n",
    "labels['y_size'] = y_size\n",
    "\n",
    "bins = np.linspace(-8, 8, 21)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "group1 = labels[(labels['pt'] > 0) & (labels['pt'] < 0.2)]\n",
    "group2 = labels[(labels['pt'] > -0.2) & (labels['pt'] < 0)]\n",
    "group3 = labels[(labels['pt'] > 0.2) | (labels['pt'] < -0.2)]\n",
    "\n",
    "def compute_bin_means(df, bins):\n",
    "    bin_means = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        lower, upper = bins[i], bins[i + 1]\n",
    "\n",
    "        if i == len(bins) - 2:\n",
    "            mask = (df['y-local'] >= lower) & (df['y-local'] <= upper)\n",
    "        else:\n",
    "            mask = (df['y-local'] >= lower) & (df['y-local'] < upper)\n",
    "\n",
    "        bin_mean = df.loc[mask, 'y_size'].mean()\n",
    "        bin_means.append(bin_mean)\n",
    "\n",
    "    return np.array(bin_means)\n",
    "\n",
    "bin_means1 = compute_bin_means(group1, bins)\n",
    "bin_means2 = compute_bin_means(group2, bins)\n",
    "bin_means3 = compute_bin_means(group3, bins)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(bin_centers, bin_means1, marker='.', linestyle='none', label=\"Low pT (pos)\")\n",
    "plt.plot(bin_centers, bin_means2, marker='.', linestyle='none', label=\"Low pT (neg)\")\n",
    "plt.plot(bin_centers, bin_means3, marker='.', linestyle='none', label=\"High pT\")\n",
    "plt.xlabel('y0')\n",
    "plt.ylabel('Cluster y size')\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_chunks)):\n",
    "    data_chunks[i] = data_chunks[i][:, -1, :, :].sum(axis = -1)\n",
    "\n",
    "n = 16\n",
    "data = np.concatenate(data_chunks[:n], axis=0)\n",
    "del data_chunks\n",
    "labels = pd.concat(labels_chunks[:n], ignore_index=True)\n",
    "del labels_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((labels['y-local'].to_numpy().reshape(-1, 1), np.count_nonzero(data, axis=1, keepdims=True), data))\n",
    "del data\n",
    "\n",
    "pt_truth = labels['pt'].to_numpy()\n",
    "del labels\n",
    "\n",
    "Y = np.zeros((pt_truth.size, 3))\n",
    "Y[:, 2] = 1\n",
    "Y[np.where((pt_truth >= 0) & (pt_truth < 0.2))] = [1, 0, 0]\n",
    "Y[np.where((pt_truth < 0) & (pt_truth > -0.2))] = [0, 1, 0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(np.sum(Y, axis=0))\n",
    "print(pt_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_idx = np.where(Y[:, 0] == 1)[0]\n",
    "class1_idx = np.where(Y[:, 1] == 1)[0]\n",
    "class2_idx = np.where(Y[:, 2] == 1)[0]\n",
    "\n",
    "min_count = min(len(class0_idx), len(class1_idx), len(class2_idx))\n",
    "\n",
    "chosen_class0 = np.random.choice(class0_idx, min_count, replace=False)\n",
    "chosen_class1 = np.random.choice(class1_idx, min_count, replace=False)\n",
    "chosen_class2 = np.random.choice(class2_idx, min_count, replace=False)\n",
    "\n",
    "balanced_idx = np.concatenate([chosen_class0, chosen_class1, chosen_class2])\n",
    "\n",
    "np.random.shuffle(balanced_idx)\n",
    "\n",
    "X_balanced = X[balanced_idx]\n",
    "Y_balanced = Y[balanced_idx]\n",
    "pt_truth_balanced = pt_truth[balanced_idx]\n",
    "\n",
    "all_indices = np.arange(Y.shape[0])\n",
    "rest_idx = np.setdiff1d(all_indices, balanced_idx)\n",
    "\n",
    "X_rest = X[rest_idx]\n",
    "Y_rest = Y[rest_idx]\n",
    "pt_truth_rest = pt_truth[rest_idx]\n",
    "\n",
    "del X, Y, pt_truth\n",
    "\n",
    "print(X_balanced.shape)\n",
    "print(Y_balanced.shape)\n",
    "print(np.sum(Y_balanced, axis=0))\n",
    "print(pt_truth_balanced.shape)\n",
    "\n",
    "print(X_rest.shape)\n",
    "print(Y_rest.shape)\n",
    "print(np.sum(Y_rest, axis=0))\n",
    "print(pt_truth_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.05\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X_balanced, Y_balanced, test_size = test_ratio, random_state = 42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 42)\n",
    "\n",
    "pt_truth_train_val, pt_truth_test = train_test_split(pt_truth_balanced, test_size = test_ratio, random_state = 42)\n",
    "\n",
    "X_test = np.concatenate((X_test, X_rest), axis=0)\n",
    "Y_test = np.concatenate((Y_test, Y_rest), axis=0)\n",
    "pt_truth_test = np.concatenate((pt_truth_test, pt_truth_rest), axis=0)\n",
    "\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('X_val   shape: ' + str(X_val.shape))\n",
    "print('X_test  shape: ' + str(X_test.shape))\n",
    "print('Y_train shape: ' + str(Y_train.shape))\n",
    "print('Y_val   shape: ' + str(Y_val.shape))\n",
    "print('Y_test  shape: ' + str(Y_test.shape))\n",
    "print('pt_truth_test  shape: ' + str(pt_truth_test.shape))\n",
    "\n",
    "del X_balanced, Y_balanced, pt_truth_balanced, X_rest, Y_rest, pt_truth_rest, X_train_val, Y_train_val, pt_truth_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('Y_val.npy', Y_val)\n",
    "np.save('Y_test.npy', Y_test)\n",
    "np.save('pt_truth_test.npy', pt_truth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-pixel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
